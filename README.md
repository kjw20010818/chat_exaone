# EXAONE-4.0-32B Chatbot
------------------------

#### ì´ í”„ë¡œì íŠ¸ëŠ” EXAONE-4.0-32B ì–¸ì–´ëª¨ë¸ì„ Hugging Face transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ë¶ˆëŸ¬ì˜¤ê³ ,
Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ ê°„ë‹¨í•˜ê²Œ ëŒ€í™”í•  ìˆ˜ ìˆë„ë¡ ë§Œë“  ì˜ˆì œì…ë‹ˆë‹¤.

#### ğŸš€ Features

ëŒ€í˜• ì–¸ì–´ëª¨ë¸(EXAONE 32B) ì§€ì›

ì–‘ìí™”(8bit/4bit) ì˜µì…˜ìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ì ˆì•½

ëŒ€í™” ë§¥ë½ ìœ ì§€ (Chat Template ê¸°ë°˜)

ì›¹ UI (Gradio) ì œê³µ â†’ ì‹¤ì‹œê°„ ì±„íŒ… ê°€ëŠ¥

ìƒì„± íŒŒë¼ë¯¸í„° ì¡°ì ˆ

temperature: ì°½ì˜ì„± ì¡°ì ˆ

top_p: í™•ë¥ ì  ìƒ˜í”Œë§

max_new_tokens: ë‹µë³€ ìµœëŒ€ ê¸¸ì´ ì„¤ì •

ğŸ“¦ Installation
1. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch transformers bitsandbytes gradio


âš ï¸ GPU í™˜ê²½ (ì˜ˆ: A100)ì—ì„œ ì‹¤í–‰ ê¶Œì¥

#### â–¶ï¸ Usage
##### 1. ì„œë²„ ì‹¤í–‰
    python chat_exaone.py

##### 2. ì›¹ ë¸Œë¼ìš°ì € ì ‘ì†
    http://localhost:7860

##### ğŸ’» Code Overview
###### ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

    model_id = "LGAI-EXAONE/EXAONE-4.0-32B"
    tokenizer = AutoTokenizer.from_pretrained(model_id)

    bnb_config = BitsAndBytesConfig(load_in_8bit=True)

    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        device_map="auto",
        torch_dtype=torch.float16,
        quantization_config=bnb_config
    )

###### ì±„íŒ… í•¨ìˆ˜
def chat_fn(message, history):
    chat_history.append({"role": "user", "content": message})

    prompt = tokenizer.apply_chat_template(chat_history, tokenize=False, add_generation_prompt=True)
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    outputs = model.generate(
       **inputs,
       max_new_tokens=512,
       do_sample=True,
       temperature=0.7,
       top_p=0.9
    )

    reply = tokenizer.decode(outputs[0][inputs["input_ids"].shape[1]:], skip_special_tokens=True).strip()
    chat_history.append({"role": "assistant", "content": reply})
    return reply

    Gradio UI
    import gradio as gr

    demo = gr.ChatInterface(fn=chat_fn)
    demo.launch(server_name="0.0.0.0", server_port=7860)

##âš–ï¸ Notes
---------
###### ì–‘ìí™”(Quantization)

load_in_8bit=True: ë©”ëª¨ë¦¬ ì ˆì•½ + ì†ë„ í–¥ìƒ

load_in_4bit=True: VRAMì´ ë¶€ì¡±í•  ê²½ìš° ì‚¬ìš© (ì •ë°€ë„ ì•½ê°„ ì†ì‹¤ ê°€ëŠ¥)

GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

FP16: ë§¤ìš° í¼ (32B ëª¨ë¸ì€ ë‹¨ì¼ GPU ë¶ˆê°€)

8bit: ì ˆë°˜ ìˆ˜ì¤€

4bit: 1/4 ìˆ˜ì¤€

## ğŸ“œ License
-------------
ë³¸ í”„ë¡œì íŠ¸ëŠ” ì—°êµ¬/í•™ìŠµ ëª©ì ì˜ ì˜ˆì œ ì½”ë“œì…ë‹ˆë‹¤.
ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì‚¬ìš©í•  ê²½ìš° ëª¨ë¸ ë¼ì´ì„ ìŠ¤ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.
